# Awesome-Explanation-Assisted-Learning
This repo is a paper collection of explanation assisted learning topic(explanation guided learning). 


### Survey
- [2024] [ACM] Gao, Yuyang, et al. Going beyond xai: A systematic survey for explanation-guided learning. [[paper]](https://arxiv.org/pdf/2212.03954)


### Conference
- [2025] [ICML] Osman Berke Guney, et al. Active feature acquisition via explainability-driven ranking[[paper]](https://openreview.net/forum?id=J8YRdm39jn)
- [2025] [ICLR] Junqi Jiang, et al. Interpreting Language Reward Models via Contrastive Explanations[[paper]](https://openreview.net/forum?id=i8IwcQBi74)
- [2025] [ICLR] Hanning Guo, et al. XAIguiFormer: explainable artificial intelligence guided transformer for brain disorder identification. [[paper]](https://openreview.net/forum?id=AD5yx2xq8R)
- [2025] [ICLR] Lirong Wu, et al. A Simple yet Effective $\Delta \Delta G$ Predictor is An Unsupervised Antibody Optimizer and Explainer. [[paper]](https://openreview.net/forum?id=IxmWIkcKs5)
- [2025] [ICLR] Shicheng Liu, et al. UTILITY: Utilizing Explainable Reinforcement Learning to Improve Reinforcement Learning. [[paper]](https://openreview.net/forum?id=Tk1VQDadfL)
- [2024] [NIPS] Jiang  Nan, et al. LeDex: Training LLMs to Better Self-Debug and Explain Code.[[paper]](https://openreview.net/forum?id=d1XrZ4EINV)
- [2024] [NIPS] Yuefei Lyu, et al. Enhancing Robustness of Graph Neural Networks on Social Media with Explainable Inverse Reinforcement Learning. [paper](https://openreview.net/pdf?id=ziehA15y8k)
- [2024] [NIPS] Yingjun Du, et al. IPO: Interpretable Prompt Optimization for Vision-Language Models. [paper](https://openreview.net/pdf?id=WPPC7FHtaM)
- [2024] [NIPS] Farnoush Rezaei Jafari, et al. MambaLRP: Explaining Selective State Space Sequence Models. [paper](https://openreview.net/pdf?id=2n1Ysn1EDl)
- [2024] [NIPS] Rohan Paleja, et al. Designs for Enabling Collaboration in Human-Machine Teaming via Interactive and Explainable Systems. [paper](https://openreview.net/pdf?id=XrK4JK2jBr)
- [2024] [NIPS] Jason Gross, et al. Compact Proofs of Model Performance via Mechanistic Interpretability. [paper](https://openreview.net/pdf?id=2zWbzx50mH)
- [2024] [NIPS] Pasan Dissanayake, Sanghamitra Dutta. Model Reconstruction Using Counterfactual Explanations: A Perspective From Polytope Theory. [paper](https://openreview.net/pdf?id=9uolDxbYLm)
- [2024] [ICML] Christian Bj√∏rn, et al. Finding NEM-U: Explaining unsupervised representation learning through neural network generated explanation masks. [[paper]](https://openreview.net/attachment?id=Hzpt1Gws9g&name=pdf)
- [2024] [ICML] Zelei Cheng, et al. RICE: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation.[[paper]](https://openreview.net/pdf?id=PKJqsZD5nQ)  [[code]](https://github.com/chengzelei/RICE)
- [2024] [ICML] Zheng Huang  et al. Enhancing Size Generalization in Graph Neural Networks through Disentangled Representation Learning. [[paper]](https://openreview.net/forum?id=0NdU4y9dWC) [[code]](https://github.com/GraphmindDartmouth/DISGEN)
- [2024] [ICLR] Zijian Feng, et al. Unveiling and manipulating prompt influence in large language models. [[paper]](https://openreview.net/pdf?id=ap1ByuwQrX) [[code]](https://github.com/zijian678/TDD).
- [2024] [ICLR] Chongyu Fan, et al. SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation. [[paper]](https://openreview.net/pdf?id=gn0mIhQGNM) [[code]](https://github.com/OPTML-Group/Unlearn-Saliency)
- [2024] [ICLR] Akari Asai, et al. Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection. [[paper]](https://openreview.net/pdf?id=hSyW5go0v8) [[code]](https://selfrag.github.io/)
- [2024] [ICLR] Anshuman Chhabra, et al. "What Data Benefits My Classifier?" Enhancing Model Performance and Interpretability through Influence-Based Data Selection. [[paper]](https://openreview.net/pdf?id=HE9eUQlAvo) [[code]](https://github.com/anshuman23/InfDataSel)


### Journal


### Other repos
- Awesome Explanatory Supervision [[link]](https://github.com/stefanoteso/awesome-explanatory-supervision)
